{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,cv2,json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import albumentations as albu\n",
    "import torch,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "device = 'cuda:0'\n",
    "sys.path.append('/rdfs/fast/home/chenyixin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(png_path):\n",
    "    img = cv2.imread(png_path)[...,::-1]\n",
    "    return {'img':img,'septum':0,'asd':0}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(pred):\n",
    "    pred_ = torch.sigmoid(pred[0,0]).detach().cpu().numpy()\n",
    "    pred_ = np.uint8(pred_ * 255)\n",
    "    # septum_[septum != 0] = 255\n",
    "    pred_ = cv2.dilate(pred_,np.ones((3,3),dtype=np.uint8),3)\n",
    "    pred_ = cv2.erode(pred_,np.ones((3,3),dtype=np.uint8),3)\n",
    "    pred_ = cv2.erode(pred_,np.ones((3,3),dtype=np.uint8),3)\n",
    "    pred_ = cv2.dilate(pred_,np.ones((3,3),dtype=np.uint8),3)\n",
    "    pred_[pred_< 25] = 0\n",
    "    pred_[pred_!= 0] = 255\n",
    "    contours,_ = cv2.findContours(pred_,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # find biggest contours\n",
    "    if len(contours) == 0:\n",
    "        return 0\n",
    "    area = []\n",
    "    for c in contours:\n",
    "        area.append(cv2.contourArea(contours[0]))\n",
    "    max_index = np.argmax(area)\n",
    "    max_cont = contours[max_index][:,0]\n",
    "    # cal biggest dis\n",
    "    return np.array([np.max(max_cont[:,0]),np.min(max_cont[:,0]),np.max(max_cont[:,1]),np.min(max_cont[:,1])])\n",
    "def create_box(arr):\n",
    "    a,b,c,d = np.max(arr[:,0]),np.min(arr[:,1]),np.max(arr[:,2]),np.min(arr[:,3])\n",
    "    width,height = a-b,c-d\n",
    "    length = max(width,height) * 1\n",
    "    ct_x = (a + b) / 2\n",
    "    ct_y = (c+d) / 2\n",
    "    a = ct_x + length / 2\n",
    "    b = ct_x - length / 2    \n",
    "    c = ct_y + length / 2    \n",
    "    d = ct_y - length / 2    \n",
    "    return a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create val_list:\n",
    "# path = '/rdfs/data/echo/chenyixin/ASD-yixin/Train_SC-2A//'\n",
    "# i = 0\n",
    "# train_data_x = []\n",
    "# train_data_y = []\n",
    "# val_data_x = []\n",
    "# val_data_y = []\n",
    "# val_list = []\n",
    "# for basepath,dirnames,files in os.walk(path):\n",
    "#     for dirname in dirnames:\n",
    "#         tmp_path = os.path.join(basepath,dirname)\n",
    "#         files = os.listdir(tmp_path)\n",
    "#         png_files = [os.path.join(basepath,dirname,i) for i in files if '.png' in i]\n",
    "        \n",
    "#         if len(png_files) == 0:\n",
    "#             continue\n",
    "#         if np.random.rand() > 0.8:\n",
    "#             val_list.append(tmp_path)\n",
    "#         i += 1\n",
    "# with open('./val_list.txt','w') as f:\n",
    "#     f.write('/n'.join(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859"
     ]
    }
   ],
   "source": [
    "path = '/rdfs/data/echo/chenyixin/ASD-yixin/Train_SC-2A//'\n",
    "with open('./val_list.txt','r') as f:\n",
    "    val_list = f.readlines()[0]\n",
    "    val_list = val_list.split('/n')\n",
    "i = 0\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "val_data_x = []\n",
    "val_data_y = []\n",
    "for basepath,dirnames,files in os.walk(path):\n",
    "    for dirname in dirnames:\n",
    "        tmp_path = os.path.join(basepath,dirname)\n",
    "        files = os.listdir(tmp_path)\n",
    "        png_files = [os.path.join(basepath,dirname,i) for i in files if '.png' in i]\n",
    "        \n",
    "        if len(png_files) == 0:\n",
    "            continue\n",
    "        png_files = sorted(png_files)\n",
    "        asd_label,asd_pred = [],[]\n",
    "        septum_label,septum_pred = [],[]\n",
    "        imgs = []\n",
    "        for png_file in png_files:\n",
    "            d = get_data(png_file)\n",
    "            input_shape = d['img'].shape[:2]\n",
    "            img = torch.tensor(d['img']/255).float().permute(2,0,1).unsqueeze(1)\n",
    "            img = F.interpolate(img,(240,320))\n",
    "            img = img[:,:,:,40:280]\n",
    "            imgs.append(img)\n",
    "        imgs = torch.cat(imgs,dim=1)\n",
    "        print('\\r' + f'{i}',end='',flush=True)\n",
    "        if tmp_path in val_list:\n",
    "            val_data_x.append(imgs)\n",
    "            if 'control' in tmp_path:\n",
    "                val_data_y.append(0)\n",
    "            else:\n",
    "                val_data_y.append(1)\n",
    "        else:\n",
    "            train_data_x.append(imgs)\n",
    "            if 'control' in tmp_path:\n",
    "                train_data_y.append(0)\n",
    "            else:\n",
    "                train_data_y.append(1)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_x,data_y,mode='train'):\n",
    "    num = len(data_x)\n",
    "    ite = 0\n",
    "    if mode == 'train':\n",
    "        max_iteration = 99999\n",
    "        index = np.random.randint(num)\n",
    "    if mode == 'val':\n",
    "        max_iteration = len(data_x)\n",
    "    while ite < max_iteration:\n",
    "        if mode == 'train':\n",
    "            index = np.random.randint(num)\n",
    "        if mode == 'val':\n",
    "            index = ite\n",
    "        x = data_x[index]\n",
    "        y = data_y[index]\n",
    "        y = torch.tensor(y).float().unsqueeze(0).unsqueeze(0)\n",
    "        if mode == 'train':\n",
    "            if x.shape[1] <= 16:\n",
    "                yield x,y\n",
    "            else:\n",
    "                start_frame = np.random.randint(x.shape[1]-16)\n",
    "                x = x[:,start_frame:start_frame + 16]\n",
    "                yield x,y\n",
    "        if mode == 'val':\n",
    "            yield x,y\n",
    "        ite += 1\n",
    "train_generator = data_generator(train_data_x,train_data_y,mode='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYMODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MYMODEL,self).__init__()\n",
    "        self.bb = torchvision.models.resnet18()\n",
    "        self.bb.avgpool = nn.Identity()\n",
    "        self.bb.fc = nn.Identity()\n",
    "        self.bb.conv1 = nn.Conv2d(3,64,7,1,3)\n",
    "        \n",
    "        self.frame_max_pooling = nn.AdaptiveMaxPool2d(output_size=(1,15))\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.permute(1,0,2,3)\n",
    "        x = self.bb.conv1(x)\n",
    "        x = self.bb.bn1(x)        \n",
    "        x = self.bb.relu(x)\n",
    "        x = self.bb.maxpool(x)\n",
    "        \n",
    "        x = self.bb.layer1(x)        \n",
    "        x = self.bb.layer2(x)        \n",
    "        x = self.bb.layer3(x)        \n",
    "        x = self.bb.layer4(x)\n",
    "        \n",
    "        x = x.permute(1,2,0,3)\n",
    "        x = self.frame_max_pooling(x)\n",
    "        x = x.permute(2,0,1,3)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        \n",
    "        x = x.squeeze(2).squeeze(2)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MYMODEL().to(device)\n",
    "# model = torch.load('./cls_model.pth')\n",
    "opt = torch.optim.Adam(model.parameters(),lr=1e-5,weight_decay=1e-4)\n",
    "bce = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def find_best_sentivity_specificity(gtA,A):\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(gtA,A)\n",
    "#     plt.plot(fpr,tpr)\n",
    "#     plt.show()\n",
    "    smallest_dis = 1\n",
    "    for i in range(len(fpr)):\n",
    "        tmp1 = fpr[i]\n",
    "        tmp2 = tpr[i]\n",
    "        dis = np.power(np.power(0-tmp1,2)+np.power(1-tmp2,2),0.5)\n",
    "        if smallest_dis > dis:\n",
    "            smallest_dis = dis\n",
    "            sen = tmp2\n",
    "            spe = 1-tmp1\n",
    "    return sen,spe,i\n",
    "def plot_roc(gt,pred):\n",
    "    auc = np.round(metrics.roc_auc_score(gt,pred),4)\n",
    "    sen,spe,i = find_best_sentivity_specificity(gt,pred)\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(gt,pred)\n",
    "    plt.plot(fpr,tpr,c= 'red',label=f'{0} ROC curve (AUROC:{0})')\n",
    "    # plt.savefig('./forpaper/20211202/ROC_817_sen709_spe771.png',dpi=300)\n",
    "    print(sen,spe,auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/137"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5951385097782108"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def val():\n",
    "    val_generator = data_generator(val_data_x,val_data_y,mode='val')  \n",
    "    LOSS = 0\n",
    "    ite = 0\n",
    "#     model.eval()\n",
    "    ys = []\n",
    "    preds = []\n",
    "    for x,y in val_generator:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            loss = bce(pred,y)\n",
    "            LOSS += loss.item() / len(val_data_x)\n",
    "            print('\\r' + f'{ite}/{len(val_data_x)}',end='',flush=True)\n",
    "            ys.append(y.item())\n",
    "            preds.append(pred.item())\n",
    "            ite += 1\n",
    "#     print(ys,preds)\n",
    "#     plot_roc(ys,preds)\n",
    "    return LOSS\n",
    "val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mnode3.ib.com\u001b[m  Mon Dec 27 13:55:46 2021\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m11818\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mchenyixin\u001b[m(\u001b[33m7295M\u001b[m) \u001b[1m\u001b[30mchenyixin\u001b[m(\u001b[33m4513M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 32'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m15691\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mrenyike\u001b[m(\u001b[33m15681M\u001b[m)\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  773\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30msongzihao\u001b[m(\u001b[33m763M\u001b[m)\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[1m\u001b[31m 55'C\u001b[m, \u001b[1m\u001b[32m 78 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m15691\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mlihui\u001b[m(\u001b[33m15681M\u001b[m)\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1521\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mgaoyufei\u001b[m(\u001b[33m1511M\u001b[m)\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m15063\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mzhuzhimin\u001b[m(\u001b[33m15051M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/137in_loss:0.33774024248123178200,val_loss:0.4962995949670347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MYMODEL. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> saved model\n",
      "136/137in_loss:0.136990755796432544400,val_loss:0.4749891007468648\n",
      "==> saved model\n",
      "136/137in_loss:0.366361409425735535600,val_loss:0.44252341825270325\n",
      "==> saved model\n",
      "136/137in_loss:0.128110840916633677800,val_loss:0.4055574450805023\n",
      "==> saved model\n",
      "136/137in_loss:0.2367957681417465271000,val_loss:0.3841601309169385\n",
      "==> saved model\n",
      "136/137ain_loss:0.0300341080874204641200,val_loss:0.36731695803902004\n",
      "==> saved model\n",
      "136/137ain_loss:0.2262320965528488281400,val_loss:0.3412637718320981\n",
      "==> saved model\n",
      "136/137ain_loss:0.0105934180319309231600,val_loss:0.38462866106016197\n",
      "136/137ain_loss:0.04324645549058914741800,val_loss:0.3398097587960099\n",
      "==> saved model\n",
      "136/137ain_loss:0.21394146978855133122000,val_loss:0.32129069133389754\n",
      "==> saved model\n",
      "136/137ain_loss:0.53179073333740236882200,val_loss:0.2818719882256331\n",
      "==> saved model\n",
      "136/137ain_loss:0.32662492990493774332400,val_loss:0.33799810388999013\n",
      "136/137ain_loss:0.07117658853530884582600,val_loss:0.2693580028296782\n",
      "==> saved model\n",
      "136/137ain_loss:0.03127517178654671582800,val_loss:0.25302071051916825\n",
      "==> saved model\n",
      "136/137ain_loss:0.031871575862169266843000,val_loss:0.24304951979382727\n",
      "==> saved model\n",
      "136/137ain_loss:0.00851106271147728723200,val_loss:0.22375685461528308\n",
      "==> saved model\n",
      "136/137ain_loss:0.22251282632350922543400,val_loss:0.23922218433470824\n",
      "136/137ain_loss:0.032835923135280618943600,val_loss:0.22166751504299595\n",
      "==> saved model\n",
      "136/137ain_loss:0.252362489700317493573800,val_loss:0.23749964289944167\n",
      "136/137ain_loss:0.004219301044940948554000,val_loss:0.20525563885517295\n",
      "==> saved model\n",
      "136/137ain_loss:0.054391331970691688544200,val_loss:0.19745592557826\n",
      "==> saved model\n",
      "136/137ain_loss:0.036696087568998348954400,val_loss:0.24222325832378216\n",
      "136/137ain_loss:0.000916304648853838454600,val_loss:0.18925145303099297\n",
      "==> saved model\n",
      "136/137ain_loss:0.012404649518430233054800,val_loss:0.1599765599703261\n",
      "==> saved model\n",
      "136/137ain_loss:0.114918313920497929965000,val_loss:0.17641952697631227\n",
      "136/137ain_loss:0.000465143588371574965200,val_loss:0.19989046114626474\n",
      "136/137ain_loss:0.009387007914483547055400,val_loss:0.16900970771068363\n",
      "136/137ain_loss:0.001832434558309614755600,val_loss:0.25464217939050976\n",
      "136/137ain_loss:0.019555032253265386535800,val_loss:0.18755132194454588\n",
      "136/137ain_loss:0.000215911335544660746000,val_loss:0.17340224886546599\n",
      "136/137ain_loss:0.009611816145479679966200,val_loss:0.2328865868130246\n",
      "136/137ain_loss:0.000687060295604169446400,val_loss:0.1805284485130537\n",
      "6466,train_loss:0.00024279918579850346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-44af2d0e6bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ite = 0\n",
    "best_val = val()\n",
    "for x,y in train_generator:\n",
    "    model.train()\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    pred = model(x)\n",
    "    loss = bce(pred,y)\n",
    "    print('\\r' + f'{ite},train_loss:{loss.item()}',end='',flush=True)\n",
    "    \n",
    "    opt.zero_grad();\n",
    "    loss.backward()-*\n",
    "    opt.step()\n",
    "    \n",
    "    ite += 1\n",
    "    if ite % 200 == 0:\n",
    "        val_loss = val()\n",
    "        print(f'{ite},val_loss:{val_loss}')\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(model,'./cls_model.pth')\n",
    "            print('==> saved model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
